{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright [2024] Stefan Dendorfer\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''We use the results from LayerNAS paper https://arxiv.org/abs/2304.11517.\n",
    "Table 3, Comparison on NATS-Bench topology search. Mean and deviation of \n",
    "test accuracy on 5 runs.'''\n",
    "\n",
    "N = 5 # this is fixed from the original data reporting 5 runs\n",
    "SF = 2 # significant figures is 2 from data\n",
    "\n",
    "table3 = {\n",
    "    \"Cifar10\": {\n",
    "        \"RS\": {\"mean\": 92.39, \"std\": 0.06},\n",
    "        \"RE\": {\"mean\": 94.13, \"std\": 0.18},\n",
    "        \"PPO\": {\"mean\": 94.02, \"std\": 0.13},\n",
    "        \"KNAS\": {\"mean\": 93.05, \"std\": 0.00},\n",
    "        \"TE-NAS\": {\"mean\": 93.90, \"std\": 0.47},\n",
    "        \"EigenNas\": {\"mean\": 93.46, \"std\": 0.02},\n",
    "        \"NASI\": {\"mean\": 93.55, \"std\": 0.10},\n",
    "        \"FairNAS\": {\"mean\": 93.23, \"std\": 0.18},\n",
    "        \"SGNAS\": {\"mean\": 93.53, \"std\": 0.12},\n",
    "        \"LayerNAS\": {\"mean\": 94.34, \"std\": 0.12}\n",
    "    },\n",
    "    \"Cifar100\": {\n",
    "        \"RS\": {\"mean\": 63.54, \"std\": 0.24},\n",
    "        \"RE\": {\"mean\": 71.40, \"std\": 0.50},\n",
    "        \"PPO\": {\"mean\": 71.68, \"std\": 0.65},\n",
    "        \"KNAS\": {\"mean\": 68.91, \"std\": 0.00},\n",
    "        \"TE-NAS\": {\"mean\": 71.24, \"std\": 0.56},\n",
    "        \"EigenNas\": {\"mean\": 71.42, \"std\": 0.63},\n",
    "        \"NASI\": {\"mean\": 71.20, \"std\": 0.14},\n",
    "        \"FairNAS\": {\"mean\": 71.00, \"std\": 1.46},\n",
    "        \"SGNAS\": {\"mean\": 70.31, \"std\": 1.09},\n",
    "        \"LayerNAS\": {\"mean\": 73.01, \"std\": 0.63}\n",
    "    },\n",
    "    \"ImageNet16-120\": {\n",
    "        \"RS\": {\"mean\": 42.71, \"std\": 0.34},\n",
    "        \"RE\": {\"mean\": 44.76, \"std\": 0.64},\n",
    "        \"PPO\": {\"mean\": 44.95, \"std\": 0.52},\n",
    "        \"KNAS\": {\"mean\": 34.11, \"std\": 0.00},\n",
    "        \"TE-NAS\": {\"mean\": 42.38, \"std\": 0.46},\n",
    "        \"EigenNas\": {\"mean\": 45.54, \"std\": 0.04},\n",
    "        \"NASI\": {\"mean\": 44.84, \"std\": 1.41},\n",
    "        \"FairNAS\": {\"mean\": 42.19, \"std\": 0.31},\n",
    "        \"SGNAS\": {\"mean\": 44.98, \"std\": 2.10},\n",
    "        \"LayerNAS\": {\"mean\": 46.58, \"std\": 0.59}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''We use two sample independent t-test.'''\n",
    "\n",
    "def welch_ttest(mean1,std1,mean2,std2, n1, n2):\n",
    "    '''This ttest is applied when the variances are not assumed similar.'''\n",
    "    # Calculate the t-statistic\n",
    "    t_value = (mean1 - mean2) / math.sqrt((std1**2 / n1) + (std2**2 / n2))\n",
    "\n",
    "    # Calculate the degrees of freedom\n",
    "    df_numerator = ((std1**2 / n1) + (std2**2 / n2))**2\n",
    "    df_denominator = ((std1**2 / n1)**2 / (n1-1)) + ((std2**2 / n2)**2 / (n2-1))\n",
    "    df = df_numerator / df_denominator\n",
    "\n",
    "    # Calculate the p-value\n",
    "    p_value = t.sf(abs(t_value), df) * 2  # two-tailed test\n",
    "    return p_value\n",
    "\n",
    "def ind_ttest(mean1,std1,mean2,std2, n1, n2):\n",
    "    '''This ttest is applied when the variances are assumed similar.'''\n",
    "    df = n1+n2 - 2\n",
    "    pooled_std = ((n1-1)*(std1 ** 2) + (n2-1)*(std2 ** 2)) / (df)\n",
    "    \n",
    "    mean_diff = (mean1 - mean2)\n",
    "    t_value = mean_diff / math.sqrt((1/n1)+(1/n2)) / (pooled_std ** 0.5)\n",
    "    \n",
    "    p_value = t.sf(abs(t_value), df) * 2  # two-tailed test\n",
    "    return p_value\n",
    "\n",
    "\n",
    "def get_pvalue(dataset, algorithm_1, algorithm_2):\n",
    "    '''Applies the two sample t-test depending on similarity of variances.'''\n",
    "    mean1 = table3[dataset][algorithm_1][\"mean\"]\n",
    "    std1_biased = table3[dataset][algorithm_1][\"std\"]\n",
    "    std1 = std1_biased * N / (N-1) # correcting for the population\n",
    "\n",
    "    \n",
    "    mean2 = table3[dataset][algorithm_2][\"mean\"]\n",
    "    std2_biased = table3[dataset][algorithm_2][\"std\"]\n",
    "    std2 = std2_biased * N / (N-1) # correcting for the population\n",
    "    \n",
    "    use_welch = std1 > 2*std2 or std2 > 2*std1\n",
    "    if use_welch:\n",
    "        # variances not similar\n",
    "        p_value = welch_ttest(mean1,std1,mean2,std2,N,N)\n",
    "    else:\n",
    "        # variances similar\n",
    "        p_value = ind_ttest(mean1,std1,mean2,std2,N,N)\n",
    "    return p_value, use_welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cifar10\n",
      "   Comparing LayerNAS with RE:\n",
      "\tNo statistical significance(p >= 0.0042): p=0.12\n",
      "   Comparing RE with PPO:\n",
      "\tNo statistical significance(p >= 0.0042): p=0.4\n",
      "   Comparing PPO with TE-NAS (using welch):\n",
      "\tNo statistical significance(p >= 0.0042): p=0.68\n",
      "   Comparing TE-NAS with NASI (using welch):\n",
      "\tNo statistical significance(p >= 0.0042): p=0.26\n",
      "Dataset: Cifar100\n",
      "   Comparing LayerNAS with PPO:\n",
      "\tNo statistical significance(p >= 0.0042): p=0.03\n",
      "   Comparing PPO with RE:\n",
      "\tNo statistical significance(p >= 0.0042): p=0.56\n",
      "   Comparing RE with TE-NAS:\n",
      "\tNo statistical significance(p >= 0.0042): p=0.71\n",
      "   Comparing TE-NAS with NASI (using welch):\n",
      "\tNo statistical significance(p >= 0.0042): p=0.91\n",
      "Dataset: ImageNet16-120\n",
      "   Comparing LayerNAS with PPO:\n",
      "\tNo statistical significance(p >= 0.0042): p=0.006\n",
      "   Comparing PPO with NASI (using welch):\n",
      "\tNo statistical significance(p >= 0.0042): p=0.9\n",
      "   Comparing NASI with RE (using welch):\n",
      "\tNo statistical significance(p >= 0.0042): p=0.93\n",
      "   Comparing RE with TE-NAS:\n",
      "\tStatistical significance(p < 0.0042): p=0.00064\n"
     ]
    }
   ],
   "source": [
    "'''Here, we compare pairwise the algorithm with the the next best one'''\n",
    "\n",
    "# choose which algorithms to compare\n",
    "algorithms = [\"RE\", \"PPO\", \"TE-NAS\", \"NASI\", \"LayerNAS\"]\n",
    "\n",
    "# choose which datasets to evaluate \n",
    "datasets = [\"Cifar10\", \"Cifar100\", \"ImageNet16-120\"]\n",
    "\n",
    "# choose a threshold for statistical significance\n",
    "# we apply bonferroni correction by dividing through the number of comparisons\n",
    "p_threshold = 0.05 / (len(datasets)*(len(algorithms)-1))\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    algorithms.sort(key=lambda x: table3[dataset][x][\"mean\"], reverse=True)\n",
    "    \n",
    "    for i in range(len(algorithms)-1):\n",
    "        best_alg = algorithms[i]\n",
    "        second_best_alg = algorithms[i+1]\n",
    "        \n",
    "        print(f\"   Comparing {best_alg} with {second_best_alg}\", end=\"\")\n",
    "        \n",
    "        p_value, use_welch = get_pvalue(dataset, best_alg, second_best_alg)\n",
    "        if use_welch:\n",
    "            print(\" (using welch)\", end=\"\")\n",
    "        print(\":\") \n",
    "        \n",
    "        if p_value < p_threshold:\n",
    "            print(\"\\tStatistical significance\"\n",
    "                  f\"(p < {p_threshold:.{SF}g}): p={p_value:.{SF}g}\")\n",
    "        else:\n",
    "            print(\"\\tNo statistical significance\"\n",
    "                  f\"(p >= {p_threshold:.{SF}g}): p={p_value:.{SF}g}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonferroni corrected threshold: 0.005\n",
      "Dataset: Cifar10\n",
      "             LayerNAS      RE      PPO TE-NAS      NASI\n",
      "0  LayerNAS         -    0.12    0.012   0.17  1.8e-05*\n",
      "1        RE      0.12       -      0.4   0.45    0.001*\n",
      "2       PPO     0.012     0.4        -   0.68   0.0009*\n",
      "3    TE-NAS      0.17    0.45     0.68      -      0.26\n",
      "4      NASI  1.8e-05*  0.001*  0.0009*   0.26         -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Here, we compare algorithms after ordering by performance with each other.'''\n",
    "\n",
    "# In the paper we only publish comparison on Cifar10 and part of the algorithms.\n",
    "# Comparing all would lower threshold even more, making it even harder to have\n",
    "# statistical significance.\n",
    "\n",
    "datasets = [\"Cifar10\"]\n",
    "algorithms = [\"RE\", \"PPO\", \"TE-NAS\", \"NASI\", \"LayerNAS\"]\n",
    "\n",
    "p_threshold = 0.05 / (len(datasets)*len(algorithms)*(len(algorithms)-1)/2)\n",
    "print(f\"Bonferroni corrected threshold: {p_threshold:.{SF}g}\")\n",
    "\n",
    "\n",
    "tables = {}\n",
    "for dataset in datasets:\n",
    "    algorithms.sort(key=lambda x: table3[dataset][x][\"mean\"], reverse=True)\n",
    "    table_data = []\n",
    "    for i in range(len(algorithms)):\n",
    "        row = []\n",
    "        for j in range(len(algorithms)):\n",
    "            if i != j:\n",
    "                p_value, _ = get_pvalue(dataset, algorithms[i], algorithms[j])\n",
    "                significant = \"*\" if p_value<p_threshold else \"\"\n",
    "                entry = f\"{p_value:.{SF}g}\" + significant\n",
    "                row.append(entry)\n",
    "            else:\n",
    "                row.append(\"-\")\n",
    "        table_data.append([algorithms[i]]+row)\n",
    "\n",
    "    tables[dataset] = pd.DataFrame(table_data, columns=[\"\"]+algorithms)\n",
    "\n",
    "# Displaying the tables\n",
    "for dataset, table in tables.items():\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    print(table)\n",
    "    print()\n",
    "\n",
    "# Latex print for paper\n",
    "# print(tables[\"Cifar10\"].to_latex(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
